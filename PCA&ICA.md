## PCA (能量最大)
**高维数据降维**
**优化目标：选择k个单位正交基，使得原始数据变换到这些基上后，各特征亮亮协方差为0，每一特征方差尽可能大**
***
### 1 原理
### 1.1 数据的表示方式-----向量
    以二维空间为例，空间中的一个点可以表示为一个二维向量，向量中的每个值分别是向量在以坐标轴为基方向上的投影。上升到多维空间，分别是向量在每个基方向上的投影值。
### 1.2 矩阵相乘
意义：右边矩阵的每一列向量变换到左边矩阵以行为基所表示的空间中。
### 1.3 方差(variance)

### 1.4 协方差 (covariance)

### 1.5 协方差矩阵
方差与协方差统一到同一矩阵。
### 1.6 协方差矩阵对角化
### 1.7 利用p矩阵对高维数据降维
***
### 2 实现过程 
设有m条n维数据，现在要利用PCA降到k维：

- 将原始数据按照n行m列组成矩阵X
- 按行(一维特征)对X进行零均值化(减去每一行的均值)
- 求矩阵X的协方差矩阵C
- 求协方差矩阵C的特征值和对应的特征向量
- 将特征向量按照特征值从大到小的顺序按行排列。取前k行组成矩阵p
- Y = pX 即为降到k维后的数据




##2. PCA与ICA的区别
### 2.1 原理介绍 
（1）PCA假设原信号间彼此非相关，ICA假设原信号间彼此独立
（2）PCA认为主元之间彼此正交，样本呈高斯分布；ICA则不要求样本呈高斯分布。

在利用最大化信息熵的方法进行独立成分分析的时候，需要为源信号假定一个概率密度分布函数g'，进而找出使得g(Y)=g(Wx)的信息熵最大的变换W，即有Y=s


###2.2 实例分析
一般鸡尾酒会（即盲源分离）问题的处理procedure
#### 2.2.1 信号源
对于一组分别为正弦、余弦、随机信号的三个模拟信号，如图2.1所示。
![这里写图片描述](http://img.blog.csdn.net/20161202224245141)
                        Figure 2.1 信号源


#### 2.2.2 信号源随机混合
信号源随机混合，使用6个麦克风对信号进行采集。采集效果如图2.3所示。
![这里写图片描述](http://img.blog.csdn.net/20161202224904098)

Figure 2.2 信号源混合后效果图

####2.2.3 白化

分解信号之前，首先需要对信号进行预处理，方法包括PCA和白化。预处理的目的是对原始信号降维，降低ICA的计算量。6路信号经过预处理后降为3路信号，如图2.3所示。ICA仅仅需要这3路信号就可以还原信号源。
![这里写图片描述] (http://img.blog.csdn.net/20161202225822329)
Figure 2.3 信号源混合后效果图
#### 2.2.4 ICA迭代求解
ICA经过多步迭代寻优，就会按照信号之间独立最大的假设，将信号解混输出。结果如图2.4所示。
![Figure2.4 恢复信号源](http://img.blog.csdn.net/20161202230256523)


总的来说，ICA认为观测信号是若干个统计独立的分量的线性组合，ICA要做的是一个解混过程。而PCA是一个信息提取的过程，将原始数据降维，现已成为ICA将数据标准化的预处理步骤。
#PCA(主成分分析)
拉格朗日



#ICA（独立成分分析）

最优化过程：利用极大似然法


